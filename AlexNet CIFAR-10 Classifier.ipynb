{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_ind = torch.arange(0, 48000)\n",
    "valid_ind = torch.arange(48000,50000)\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((70,70)),\n",
    "                                       transforms.RandomCrop((64,64)),\n",
    "                                       transforms.ToTensor()])\n",
    "test_transforms = transforms.Compose([transforms.Resize((70,70)),\n",
    "                                       transforms.RandomCrop((64,64)),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "train_valid = datasets.CIFAR10(root='data', train=True, transform=train_transforms, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='data',train=False,transform=test_transforms,download=False)\n",
    "train_dataset = Subset(train_valid,train_ind)\n",
    "valid_dataset = Subset(train_valid,valid_ind)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,num_workers=4,shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset,batch_size=batch_size,num_workers=4,shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,num_workers=4,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Image batch dimensions: torch.Size([128, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([128])\n",
      "\n",
      "Validation Set:\n",
      "Image batch dimensions: torch.Size([128, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([128])\n",
      "\n",
      "Testing Set:\n",
      "Image batch dimensions: torch.Size([128, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([128])\n",
      "375\n",
      "16\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "print('Training Set:')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break\n",
    "    \n",
    "# Checking the dataset\n",
    "print('\\nValidation Set:')\n",
    "for images, labels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "print('\\nTesting Set:')\n",
    "for images, labels in test_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(valid_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,64,kernel_size=11,stride=4,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.features(x)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(-1,256*6*6)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "model = AlexNet(10)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_acc(net, data_loader):\n",
    "    net.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            proba = net(features)\n",
    "            _, predicted = torch.max(proba, 1)\n",
    "            num_examples +=targets.size(0)\n",
    "            correct_pred += (predicted == targets).sum()\n",
    "        return correct_pred.float()/num_examples*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/375 |Loss: 2.3025\n",
      "Epoch: 001/010 | Batch 150/375 |Loss: 1.8892\n",
      "Epoch: 001/010 | Batch 300/375 |Loss: 1.6252\n",
      "Epoch: 001/010\n",
      "Train ACC: 39.59 | Validation ACC: 38.60\n",
      "Time elapsed: 0.38 min\n",
      "Epoch: 002/010 | Batch 000/375 |Loss: 1.6223\n",
      "Epoch: 002/010 | Batch 150/375 |Loss: 1.4762\n",
      "Epoch: 002/010 | Batch 300/375 |Loss: 1.2915\n",
      "Epoch: 002/010\n",
      "Train ACC: 50.45 | Validation ACC: 51.05\n",
      "Time elapsed: 0.76 min\n",
      "Epoch: 003/010 | Batch 000/375 |Loss: 1.3748\n",
      "Epoch: 003/010 | Batch 150/375 |Loss: 1.4022\n",
      "Epoch: 003/010 | Batch 300/375 |Loss: 1.2968\n",
      "Epoch: 003/010\n",
      "Train ACC: 58.18 | Validation ACC: 57.05\n",
      "Time elapsed: 1.15 min\n",
      "Epoch: 004/010 | Batch 000/375 |Loss: 1.2011\n",
      "Epoch: 004/010 | Batch 150/375 |Loss: 1.1653\n",
      "Epoch: 004/010 | Batch 300/375 |Loss: 1.1628\n",
      "Epoch: 004/010\n",
      "Train ACC: 63.55 | Validation ACC: 62.00\n",
      "Time elapsed: 1.54 min\n",
      "Epoch: 005/010 | Batch 000/375 |Loss: 0.8413\n",
      "Epoch: 005/010 | Batch 150/375 |Loss: 1.0527\n",
      "Epoch: 005/010 | Batch 300/375 |Loss: 1.0130\n",
      "Epoch: 005/010\n",
      "Train ACC: 67.22 | Validation ACC: 64.85\n",
      "Time elapsed: 1.93 min\n",
      "Epoch: 006/010 | Batch 000/375 |Loss: 0.8613\n",
      "Epoch: 006/010 | Batch 150/375 |Loss: 0.9093\n",
      "Epoch: 006/010 | Batch 300/375 |Loss: 0.9957\n",
      "Epoch: 006/010\n",
      "Train ACC: 68.56 | Validation ACC: 64.40\n",
      "Time elapsed: 2.31 min\n",
      "Epoch: 007/010 | Batch 000/375 |Loss: 0.9383\n",
      "Epoch: 007/010 | Batch 150/375 |Loss: 0.7644\n",
      "Epoch: 007/010 | Batch 300/375 |Loss: 0.8931\n",
      "Epoch: 007/010\n",
      "Train ACC: 71.71 | Validation ACC: 65.35\n",
      "Time elapsed: 2.69 min\n",
      "Epoch: 008/010 | Batch 000/375 |Loss: 0.8270\n",
      "Epoch: 008/010 | Batch 150/375 |Loss: 0.9008\n",
      "Epoch: 008/010 | Batch 300/375 |Loss: 0.8067\n",
      "Epoch: 008/010\n",
      "Train ACC: 74.76 | Validation ACC: 68.70\n",
      "Time elapsed: 3.07 min\n",
      "Epoch: 009/010 | Batch 000/375 |Loss: 0.7325\n",
      "Epoch: 009/010 | Batch 150/375 |Loss: 0.8516\n",
      "Epoch: 009/010 | Batch 300/375 |Loss: 0.7274\n",
      "Epoch: 009/010\n",
      "Train ACC: 78.17 | Validation ACC: 71.15\n",
      "Time elapsed: 3.45 min\n",
      "Epoch: 010/010 | Batch 000/375 |Loss: 0.6555\n",
      "Epoch: 010/010 | Batch 150/375 |Loss: 0.5681\n",
      "Epoch: 010/010 | Batch 300/375 |Loss: 0.7506\n",
      "Epoch: 010/010\n",
      "Train ACC: 79.34 | Validation ACC: 71.10\n",
      "Time elapsed: 3.83 min\n",
      "Total Training Time: 3.83 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "loss_list = []\n",
    "train_list = []\n",
    "valid_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_ind,(features, targets) in enumerate(train_loader):\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        out = model(features)\n",
    "        loss = criterion(out, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        if not batch_ind % 150:\n",
    "            print (f'Epoch: {epoch+1:03d}/{num_epochs:03d} | '\n",
    "                   f'Batch {batch_ind:03d}/{len(train_loader):03d} |' \n",
    "                   f'Loss: {loss:.4f}')\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        \n",
    "        train_acc = metric_acc(model, train_loader)\n",
    "        valid_acc = metric_acc(model, valid_loader)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}\\n'\n",
    "              f'Train ACC: {train_acc:.2f} | Validation ACC: {valid_acc:.2f}')\n",
    "        \n",
    "        train_list.append(train_acc)\n",
    "        valid_list.append(valid_acc)\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 70.75%\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: %.2f%%' % (metric_acc(model, test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
